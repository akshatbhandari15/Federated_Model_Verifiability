
Malicious Devices:  [5]
Client Labels:  dict_keys([0, 1, 2, 5, 8, 4, 7, 6, 3, 9])
Client Indexes to use:  [0, 4, 1, 6, 3, 2, 9, 7]
All Labels:  dict_keys([5, 0, 4, 1, 9, 2, 3, 6, 7, 8])
CR:   0%|                                                                                                         | 0/5 [00:00<?, ?it/s]/home/akshat/.local/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(for 0:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]








TModel Training for 0: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [01:32<00:00,  7.97s/it]






Traceback (most recent call last):████████████████████████████████████████████████████████████████████████| 8/8 [00:28<00:00,  4.42s/it]
  File "/home/akshat/project/train_loop.py", line 195, in <module>
    train_object.train()
  File "/home/akshat/project/train_loop.py", line 125, in train
    for _, (data, targets) in enumerate(train_loader):
  File "/home/akshat/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 633, in __next__
    data = self._next_data()
  File "/home/akshat/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 677, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/akshat/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/akshat/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/akshat/.local/lib/python3.9/site-packages/torch/utils/data/dataset.py", line 298, in __getitem__
    return self.dataset[self.indices[idx]]
  File "/home/akshat/.local/lib/python3.9/site-packages/torchvision/datasets/mnist.py", line 145, in __getitem__
    img = self.transform(img)
  File "/home/akshat/.local/lib/python3.9/site-packages/torchvision/transforms/transforms.py", line 95, in __call__
    img = t(img)
  File "/home/akshat/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/akshat/.local/lib/python3.9/site-packages/torchvision/transforms/transforms.py", line 277, in forward
    return F.normalize(tensor, self.mean, self.std, self.inplace)
  File "/home/akshat/.local/lib/python3.9/site-packages/torchvision/transforms/functional.py", line 363, in normalize
    return F_t.normalize(tensor, mean=mean, std=std, inplace=inplace)
KeyboardInterrupt